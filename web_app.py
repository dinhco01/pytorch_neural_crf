import streamlit as st
import pandas as pd
import random
import nltk
from typing import Dict, List
import plotly.express as px
from collections import Counter

try:
    from transformers_predictor import TransformersNERPredictor
    from ner_predictor import NERPredictor
except ImportError:
    st.error("Kh√¥ng th·ªÉ import c√°c module.")
    st.stop()

st.set_page_config(
    page_title="Named Entity Recognition cho vƒÉn b·∫£n L·ªãch S·ª≠ Vi·ªát Nam",
    page_icon="üèõÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown(
    """
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }

    .entity-box {
        padding: 4px 10px;
        border-radius: 15px;
        margin: 3px;
        display: inline-block;
        font-weight: bold;
        color: white;
        font-size: 0.9rem;
        box-shadow: 0 3px 6px rgba(0,0,0,0.25);
        transition: all 0.3s ease;
        border: 1px solid rgba(255,255,255,0.3);
        text-shadow: 0 1px 2px rgba(0,0,0,0.3);
    }

    .entity-box:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.4);
        filter: brightness(1.1);
    }

    .entity-PER {
        background: linear-gradient(135deg, #e74c3c 0%, #c0392b 50%, #a93226 100%);
        border-color: #d63031;
    }
    .entity-LOC {
        background: linear-gradient(135deg, #27ae60 0%, #229954 50%, #1e8449 100%);
        border-color: #00b894;
    }
    .entity-TME {
        background: linear-gradient(135deg, #3498db 0%, #2980b9 50%, #21618c 100%);
        border-color: #74b9ff;
    }
    .entity-TITLE {
        background: linear-gradient(135deg, #f39c12 0%, #e67e22 50%, #d35400 100%);
        border-color: #fdcb6e;
    }
    .entity-NUM {
        background: linear-gradient(135deg, #9b59b6 0%, #8e44ad 50%, #7d3c98 100%);
        border-color: #a29bfe;
    }

    .prediction-box {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #1f77b4;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        line-height: 2;
        font-size: 1.1rem;
    }

    .metric-card {
        background: linear-gradient(135deg, #ffffff, #f8f9fa);
        padding: 1.5rem;
        border-radius: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        text-align: center;
        border: 1px solid #e9ecef;
        height: 120px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        transition: transform 0.3s ease;
        margin-bottom: 1rem;
    }

    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.15);
    }

    .sample-text {
        background: linear-gradient(135deg, #fff3cd, #ffeaa7);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #ffc107;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }

    .legend-container {
        background: linear-gradient(135deg, #f8f9fa, #ffffff);
        padding: 1.2rem;
        border-radius: 15px;
        border: 1px solid #e9ecef;
        box-shadow: 0 3px 8px rgba(0,0,0,0.1);
    }

    .legend-item {
        display: flex;
        align-items: center;
        margin: 8px 0;
        font-size: 0.95rem;
        font-weight: 500;
    }

    .legend-label {
        margin-left: 10px;
        color: #2d3436;
    }

    .stMetric {
        background: none !important;
    }

    .stMetric > div {
        background: none !important;
    }
</style>
""",
    unsafe_allow_html=True,
)

# Kh·ªüi t·∫°o session state
if "predictor" not in st.session_state:
    st.session_state.predictor = None
if "model_type" not in st.session_state:
    st.session_state.model_type = None
if "sample_data" not in st.session_state:
    st.session_state.sample_data = None
if "user_input_text" not in st.session_state:
    st.session_state.user_input_text = ""


def clean_punctuation(tokens) -> str:
    if not isinstance(tokens, list):
        return tokens

    punctuation_marks = [".", ",", "?", "!", ":", ";"]
    new_tokens = list(tokens)

    i = len(new_tokens) - 1
    while i > 0:
        if new_tokens[i] in punctuation_marks:
            new_tokens[i - 1] += new_tokens[i]
            del new_tokens[i]
        i -= 1

    return " ".join(new_tokens)


# Load d·ªØ li·ªáu m·∫´u t·ª´ file CSV
@st.cache_data
def load_sample_data():
    import ast

    try:
        df = pd.read_csv("./output_data/vietnam-history-data-ner/ner_sentences.csv")
        df["tokens_eval"] = df["tokens"].apply(ast.literal_eval)
        df["sentence_length"] = df["tokens_eval"].apply(len)
        df["text"] = df["tokens_eval"].apply(clean_punctuation)
        df_sorted = df.sort_values(by="sentence_length", ascending=False).head(3000)
        sampled_1000 = df_sorted.sample(n=1000, random_state=42)
        sample_texts = sampled_1000["text"].to_list()
        return df, sample_texts
    except FileNotFoundError:
        raise FileNotFoundError(
            "Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu m·∫´u. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n!"
        )


# Load m√¥ h√¨nh
def load_model(model_type, model_path, device="cpu"):
    try:
        if model_type == "PhoBERT-CRF":
            return TransformersNERPredictor(model_path, cuda_device=device)
        elif model_type == "BiLSTM-CRF":
            return NERPredictor(model_path, cuda_device=device)
    except Exception as e:
        st.error(f"L·ªói khi load m√¥ h√¨nh: {e}")
        return None


# Highlight c√°c entities
def highlight_entities(tokens: List[str], labels: List[str]) -> str:
    """T·∫°o HTML v·ªõi highlight cho c√°c entities"""
    html_content = []
    i = 0

    while i < len(tokens):
        token = tokens[i]
        label = labels[i]

        if label.startswith("B-"):
            # B·∫Øt ƒë·∫ßu entity m·ªõi
            entity_type = label[2:]
            entity_tokens = [token]
            j = i + 1

            # Thu th·∫≠p t·∫•t c·∫£ tokens c·ªßa entity
            while j < len(tokens) and (
                labels[j] == f"I-{entity_type}" or labels[j] == f"E-{entity_type}"
            ):
                entity_tokens.append(tokens[j])
                if labels[j] == f"E-{entity_type}":
                    j += 1
                    break
                j += 1

            entity_text = " ".join(entity_tokens)
            html_content.append(
                f'<span class="entity-box entity-{entity_type}" title="{entity_type}">{entity_text}</span>'
            )
            i = j
        else:
            # Token th∆∞·ªùng
            html_content.append(token)
            i += 1

        # Th√™m kho·∫£ng tr·∫Øng n·∫øu kh√¥ng ph·∫£i token cu·ªëi
        if i < len(tokens):
            html_content.append(" ")

    return "".join(html_content)


# Chuy·ªÉn ƒë·ªïi prediction th√†nh JSON
def predictions_to_json(tokens: List[str], labels: List[str]) -> Dict:
    entities = []
    entity_count = 0
    i = 0

    while i < len(tokens):
        label = labels[i]

        if label.startswith("B-"):
            entity_type = label[2:]
            entity_tokens = [tokens[i]]
            start_idx = i
            j = i + 1

            while j < len(tokens) and (
                labels[j] == f"I-{entity_type}" or labels[j] == f"E-{entity_type}"
            ):
                entity_tokens.append(tokens[j])
                if labels[j] == f"E-{entity_type}":
                    j += 1
                    break
                j += 1

            end_idx = j - 1
            entity_text = " ".join(entity_tokens)

            entities.append(
                {
                    "type": entity_type,
                    "text": entity_text,
                    "start": start_idx,
                    "end": end_idx,
                }
            )
            entity_count += 1
            i = j
        else:
            i += 1

    return {
        "text": " ".join(tokens),
        "total_entities": entity_count,
        "entities": entities,
        "entity_types": list(set([e["type"] for e in entities])),
    }


# So s√°nh k·∫øt qu·∫£ d·ª± ƒëo√°n v·ªõi ground truth
def compare_predictions(pred_entities: List, true_entities: List) -> Dict:
    pred_set = set((e["type"], e["text"], e["start"], e["end"]) for e in pred_entities)
    true_set = set((e["type"], e["text"], e["start"], e["end"]) for e in true_entities)

    tp = len(pred_set & true_set)  # True Positive
    fp = len(pred_set - true_set)  # False Positive
    fn = len(true_set - pred_set)  # False Negative

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = (
        2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    )

    return {
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "tp": tp,
        "fp": fp,
        "fn": fn,
    }


# Header
st.markdown(
    '<h1 class="main-header">üèõÔ∏è Named Entity Recognition</h1>', unsafe_allow_html=True
)
st.markdown(
    '<p style="text-align: center; font-size: 1.2rem; color: #666;">Ch∆∞∆°ng tr√¨nh nh·∫≠n d·∫°ng th·ª±c th·ªÉ cho vƒÉn b·∫£n L·ªãch S·ª≠ Vi·ªát Nam</p>',
    unsafe_allow_html=True,
)

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh")

    # Ch·ªçn m√¥ h√¨nh
    model_type = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh",
        ["PhoBERT-CRF", "BiLSTM-CRF"],
        help="PhoBERT-CRF: M√¥ h√¨nh transformer, BiLSTM-CRF: M√¥ h√¨nh RNN truy·ªÅn th·ªëng",
    )

    # C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh
    if model_type == "PhoBERT-CRF":
        model_path = "model_files/phobert_base"
    else:
        model_path = "model_files/bilstm/bilstm.tar.gz"

    device = st.selectbox("Thi·∫øt b·ªã", ["cpu", "cuda:0"], help="Ch·ªçn CPU ho·∫∑c GPU")

    # Load m√¥ h√¨nh
    if st.button("üîÑ Load m√¥ h√¨nh"):
        with st.spinner("ƒêang load m√¥ h√¨nh..."):
            st.session_state.predictor = load_model(model_type, model_path, device)
            st.session_state.model_type = model_type
            if st.session_state.predictor:
                st.success("M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
            else:
                st.error("Kh√¥ng th·ªÉ load m√¥ h√¨nh!")

    # Th√¥ng tin m√¥ h√¨nh
    if st.session_state.predictor:
        st.info(f"M√¥ h√¨nh hi·ªán t·∫°i: {st.session_state.model_type}")

    # Legend m√†u s·∫Øc
    st.subheader("Th√¥ng tin th·ª±c th·ªÉ")
    legend_html = """
    <div class="legend-container">
        <div class="legend-item">
            <span class="entity-box entity-PER">PER</span>
            <span class="legend-label">Ng∆∞·ªùi (Person)</span>
        </div>
        <div class="legend-item">
            <span class="entity-box entity-LOC">LOC</span>
            <span class="legend-label">ƒê·ªãa ƒëi·ªÉm (Location)</span>
        </div>
        <div class="legend-item">
            <span class="entity-box entity-TME">TME</span>
            <span class="legend-label">Th·ªùi gian (Time)</span>
        </div>
        <div class="legend-item">
            <span class="entity-box entity-TITLE">TITLE</span>
            <span class="legend-label">Ch·ª©c danh (Title)</span>
        </div>
        <div class="legend-item">
            <span class="entity-box entity-NUM">NUM</span>
            <span class="legend-label">S·ªë (Number)</span>
        </div>
    </div>
    """
    st.markdown(legend_html, unsafe_allow_html=True)

# Tabs ch√≠nh
tab1, tab2, tab3 = st.tabs(
    ["D·ª± ƒëo√°n vƒÉn b·∫£n", "Ki·ªÉm tra d·ªØ li·ªáu m·∫´u", "Th·ªëng k√™ v√† ph√¢n t√≠ch"]
)

with tab1:
    st.subheader("Nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ d·ª± ƒëo√°n")

    if not st.session_state.predictor:
        st.warning("‚ö†Ô∏è Vui l√≤ng load m√¥ h√¨nh tr∆∞·ªõc khi s·ª≠ d·ª•ng!")
    else:
        # Load sample data if not loaded
        if st.session_state.sample_data is None:
            st.session_state.sample_data = load_sample_data()[0]

        # Load sample texts for selectbox
        sample_texts = ["---Nh·∫≠p vƒÉn b·∫£n b√™n d∆∞·ªõi---"] + load_sample_data()[1]

        # Sample text selection
        selected_sample = st.selectbox("Ch·ªçn m·∫´u ƒë·ªÉ d·ª± ƒëo√°n", sample_texts)

        # Handle sample selection change
        if selected_sample != "---Nh·∫≠p vƒÉn b·∫£n b√™n d∆∞·ªõi---":
            st.session_state.user_input_text = selected_sample
        else:
            st.session_state.user_input_text = ""

        # Text input area
        user_input = st.text_area(
            "Nh·∫≠p ho·∫∑c ch·ªânh s·ª≠a vƒÉn b·∫£n",
            value=st.session_state.user_input_text,
            height=120,
            placeholder="Nh·∫≠p c√¢u vƒÉn l·ªãch s·ª≠ Vi·ªát Nam ƒë·ªÉ nh·∫≠n di·ªán th·ª±c th·ªÉ...",
            key="text_input",
        )

        # Update session state when text changes
        if user_input != st.session_state.user_input_text:
            st.session_state.user_input_text = user_input

        # Button layout - only show buttons when there's text
        if user_input.strip():
            col1, col2 = st.columns([1, 9])
            with col1:
                predict_btn = st.button("D·ª± ƒëo√°n", type="primary")
        else:
            predict_btn = False

        # Handle predict button
        if predict_btn and user_input.strip():
            with st.spinner("ƒêang x·ª≠ l√Ω..."):
                try:
                    # Tokenize
                    nltk.download("punkt_tab", quiet=True)

                    if st.session_state.model_type == "PhoBERT-CRF":
                        tokens = nltk.word_tokenize(user_input)
                        predictions = st.session_state.predictor.predict([tokens])
                        labels = predictions[0] if predictions else []
                    else:
                        predictions = st.session_state.predictor.predict(user_input)
                        tokens = nltk.word_tokenize(user_input)
                        labels = predictions if isinstance(predictions, list) else []

                    if tokens and labels:
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi highlight
                        st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n")
                        highlighted_text = highlight_entities(tokens, labels)
                        st.markdown(
                            f'<div class="prediction-box">{highlighted_text}</div>',
                            unsafe_allow_html=True,
                        )

                        # JSON output
                        json_result = predictions_to_json(tokens, labels)

                        col1, col2 = st.columns(2)

                        with col1:
                            st.subheader("Th√¥ng tin t·ªïng quan")
                            st.metric("T·ªïng s·ªë t·ª´", len(tokens))
                            st.metric("S·ªë entities", json_result["total_entities"])
                            if json_result["entity_types"]:
                                st.write(
                                    "**Lo·∫°i entities**",
                                    ", ".join(json_result["entity_types"]),
                                )

                        with col2:
                            st.subheader("JSON Output")
                            st.json(json_result)

                        # B·∫£ng chi ti·∫øt entities
                        if json_result["entities"]:
                            st.subheader("Chi ti·∫øt c√°c entities")
                            df_entities = pd.DataFrame(json_result["entities"])
                            st.dataframe(df_entities, use_container_width=True)

                except Exception as e:
                    st.error(f"L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {e}")

with tab2:
    st.subheader("Ki·ªÉm tra v·ªõi d·ªØ li·ªáu m·∫´u")

    if not st.session_state.predictor:
        st.warning("‚ö†Ô∏è Vui l√≤ng load m√¥ h√¨nh tr∆∞·ªõc khi s·ª≠ d·ª•ng!")
    else:
        # Load d·ªØ li·ªáu m·∫´u
        if st.session_state.sample_data is None:
            st.session_state.sample_data = load_sample_data()[0]

        df = st.session_state.sample_data

        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"T·ªïng s·ªë m·∫´u: {len(df)}")
        with col2:
            if st.button("üé≤ Ch·ªçn ng·∫´u nhi√™n"):
                selected_idx = random.randint(0, len(df) - 1)
            else:
                selected_idx = 0

        # T·∫°o danh s√°ch options cho selectbox v·ªõi format "index - text"
        sample_options = []
        for idx in range(len(df)):
            sample_text = df.iloc[idx]["text"]
            # Gi·ªõi h·∫°n ƒë·ªô d√†i text hi·ªÉn th·ªã ƒë·ªÉ tr√°nh selectbox qu√° d√†i
            display_text = (
                sample_text[:100] + "..." if len(sample_text) > 100 else sample_text
            )
            sample_options.append(f"{idx} - {display_text}")

        # Ch·ªçn m·∫´u v·ªõi format m·ªõi
        selected_option = st.selectbox(
            "Ch·ªçn m·∫´u:",
            sample_options,
            index=selected_idx,
            help="Ch·ªçn m·∫´u ƒë·ªÉ ki·ªÉm tra d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh",
        )

        # L·∫•y ch·ªâ s·ªë t·ª´ option ƒë∆∞·ª£c ch·ªçn
        sample_idx = int(selected_option.split(" - ")[0])
        sample = df.iloc[sample_idx]

        # Parse d·ªØ li·ªáu
        try:
            true_tokens = eval(sample["tokens"])
            true_labels = eval(sample["bio_tags"])
            true_entities = eval(sample["entities"])

            st.markdown(
                f'<div class="sample-text"><strong>ID:</strong> {sample["stc_id"]}</div>',
                unsafe_allow_html=True,
            )

            # Hi·ªÉn th·ªã ground truth
            st.subheader("Ground Truth")
            true_highlighted = highlight_entities(true_tokens, true_labels)
            st.markdown(
                f'<div class="prediction-box">{true_highlighted}</div>',
                unsafe_allow_html=True,
            )

            # D·ª± ƒëo√°n
            with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                try:
                    if st.session_state.model_type == "PhoBERT-CRF":
                        pred_result = st.session_state.predictor.predict([true_tokens])
                        pred_labels = pred_result[0] if pred_result else []
                    else:
                        text_input = " ".join(true_tokens)
                        pred_result = st.session_state.predictor.predict(text_input)
                        pred_labels = (
                            pred_result if isinstance(pred_result, list) else []
                        )

                    # Hi·ªÉn th·ªã d·ª± ƒëo√°n
                    st.subheader("D·ª± ƒëo√°n c·ªßa m√¥ h√¨nh")
                    pred_highlighted = highlight_entities(true_tokens, pred_labels)
                    st.markdown(
                        f'<div class="prediction-box">{pred_highlighted}</div>',
                        unsafe_allow_html=True,
                    )

                    # So s√°nh k·∫øt qu·∫£
                    pred_json = predictions_to_json(true_tokens, pred_labels)
                    comparison = compare_predictions(
                        pred_json["entities"], true_entities
                    )

                    st.subheader("So s√°nh k·∫øt qu·∫£")
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric("Precision", f"{comparison['precision']:.3f}")
                    with col2:
                        st.metric("Recall", f"{comparison['recall']:.3f}")
                    with col3:
                        st.metric("F1-Score", f"{comparison['f1']:.3f}")
                    with col4:
                        st.metric(
                            "Accuracy",
                            f"{comparison['tp']}/{comparison['tp'] + comparison['fp'] + comparison['fn']}",
                        )

                    # B·∫£ng so s√°nh chi ti·∫øt
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**Ground Truth Entities**")
                        if true_entities:
                            df_true = pd.DataFrame(true_entities)
                            st.dataframe(df_true)
                        else:
                            st.write("Kh√¥ng c√≥ entities")

                    with col2:
                        st.write("**Predicted Entities**")
                        if pred_json["entities"]:
                            df_pred = pd.DataFrame(pred_json["entities"])
                            st.dataframe(df_pred[["type", "text", "start", "end"]])
                        else:
                            st.write("Kh√¥ng c√≥ entities")

                except Exception as e:
                    st.error(f"L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {e}")

        except Exception as e:
            st.error(f"L·ªói khi parse d·ªØ li·ªáu: {e}")

with tab3:
    st.subheader("Th·ªëng k√™ v√† ph√¢n t√≠ch")

    if st.session_state.sample_data is not None:
        df = st.session_state.sample_data

        # Th·ªëng k√™ t·ªïng quan v·ªõi layout c·∫£i thi·ªán
        st.write("#### T·ªïng quan d·ªØ li·ªáu")

        # Parse v√† th·ªëng k√™ entities
        all_entities = []
        entity_types = []

        for _, row in df.iterrows():
            entities = eval(row["entities"])
            all_entities.extend(entities)
            entity_types.extend([e["type"] for e in entities])

        # S·ª≠ d·ª•ng columns v·ªõi metric cards t√πy ch·ªânh
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown(
                f"""
            <div class="metric-card">
                <h3 style="color: #1f77b4; margin: 0; font-size: 2rem;">{len(df)}</h3>
                <p style="margin: 0; color: #666; font-weight: bold;">T·ªïng m·∫´u</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col2:
            st.markdown(
                f"""
            <div class="metric-card">
                <h3 style="color: #e74c3c; margin: 0; font-size: 2rem;">{len(all_entities)}</h3>
                <p style="margin: 0; color: #666; font-weight: bold;">T·ªïng entities</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col3:
            st.markdown(
                f"""
            <div class="metric-card">
                <h3 style="color: #27ae60; margin: 0; font-size: 2rem;">{len(set(entity_types))}</h3>
                <p style="margin: 0; color: #666; font-weight: bold;">Lo·∫°i entities</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col4:
            avg_entities = len(all_entities) / len(df) if len(df) > 0 else 0
            st.markdown(
                f"""
            <div class="metric-card">
                <h3 style="color: #9b59b6; margin: 0; font-size: 2rem;">{avg_entities:.1f}</h3>
                <p style="margin: 0; color: #666; font-weight: bold;">Trung b√¨nh s·ªë entities/c√¢u</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        # Bi·ªÉu ƒë·ªì ph√¢n b·ªë lo·∫°i entities v·ªõi m√†u m·ªõi
        if entity_types:
            entity_counts = Counter(entity_types)

            st.write("#### Ph√¢n b·ªë c√°c lo·∫°i entities")
            col1, col2 = st.columns(2)

            with col1:
                st.write("##### T·ª∑ l·ªá c√°c lo·∫°i entities")
                fig_pie = px.pie(
                    values=list(entity_counts.values()),
                    names=list(entity_counts.keys()),
                    title="",
                    color_discrete_sequence=[
                        "#e74c3c",
                        "#27ae60",
                        "#3498db",
                        "#f39c12",
                        "#9b59b6",
                    ],
                )
                fig_pie.update_traces(textposition="inside", textinfo="percent+label")
                st.plotly_chart(fig_pie, use_container_width=True)

            with col2:
                st.write("##### S·ªë l∆∞·ª£ng theo lo·∫°i")
                fig_bar = px.bar(
                    x=list(entity_counts.keys()),
                    y=list(entity_counts.values()),
                    title="",
                    color=list(entity_counts.keys()),
                    color_discrete_sequence=[
                        "#e74c3c",
                        "#27ae60",
                        "#3498db",
                        "#f39c12",
                        "#9b59b6",
                    ],
                )
                fig_bar.update_xaxes(title="Lo·∫°i entity")
                fig_bar.update_yaxes(title="S·ªë l∆∞·ª£ng")
                fig_bar.update_layout(showlegend=False)
                st.plotly_chart(fig_bar, use_container_width=True)

        # B·∫£ng th·ªëng k√™ chi ti·∫øt
        st.write("#### Th·ªëng k√™ chi ti·∫øt")
        if entity_types:
            stats_data = []
            for entity_type in set(entity_types):
                count = entity_counts[entity_type]
                percentage = (count / len(all_entities)) * 100
                stats_data.append(
                    {
                        "Lo·∫°i Entity": entity_type,
                        "S·ªë l∆∞·ª£ng": count,
                        "T·ª∑ l·ªá (%)": f"{percentage:.1f}%",
                    }
                )

            df_stats = pd.DataFrame(stats_data)
            df_stats = df_stats.sort_values("S·ªë l∆∞·ª£ng", ascending=False)
            st.dataframe(df_stats, use_container_width=True, hide_index=True)
    else:
        st.info("Vui l√≤ng load d·ªØ li·ªáu m·∫´u ƒë·ªÉ xem th·ªëng k√™")
